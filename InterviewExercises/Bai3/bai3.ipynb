{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YJcThUdeGU5v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(2002)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ouOf86EGd-P",
        "outputId": "12bc1683-22bf-4459-ebcb-4e22fd4563ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "(10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "source": [
        "data = np.load(r\"D:\\InterviewExercises\\data\\mnist.npz\")\n",
        "x_train = data['x_train']\n",
        "y_train = data['y_train']\n",
        "x_test = data['x_test']\n",
        "y_test = data['y_test']\n",
        "\n",
        "# chuẩn hóa\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# in ra kích thước\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04vrbqCdGiCO",
        "outputId": "25a381f7-bff7-4fdf-bcfa-3e54c7522da9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 784) (60000,)\n",
            "(10000, 784) (10000,)\n"
          ]
        }
      ],
      "source": [
        "# Chuyển đổi dữ liệu từ 2D (28x28) thành 1D (784)\n",
        "x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "# in ra kích thước\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ien4DfOmGt4h",
        "outputId": "831a4811-9e63-4d69-b593-a3fee923b3cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 786) (60000,)\n",
            "(10000, 786) (10000,)\n"
          ]
        }
      ],
      "source": [
        "x_train = np.hstack([np.ones((x_train.shape[0], 1)), x_train])\n",
        "x_test = np.hstack([np.ones((x_test.shape[0], 1)), x_test])\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "OoMC7B7mR_Zp"
      },
      "outputs": [],
      "source": [
        "def generate_triplets(X, y):\n",
        "    triplets = []\n",
        "    for anchor_idx in range(len(y)):\n",
        "        anchor_label = y[anchor_idx]\n",
        "        positive_idx = np.random.choice(np.where(y == anchor_label)[0])\n",
        "        negative_idx = np.random.choice(np.where(y != anchor_label)[0])\n",
        "        triplets.append((X[anchor_idx], X[positive_idx], X[negative_idx]))\n",
        "    return np.array(triplets)\n",
        "x_train_triplets = generate_triplets(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXUYqD4nSovm",
        "outputId": "9ea6231d-4534-44c0-8a87-15c439db1849"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(786,)\n",
            "(786,)\n",
            "(786,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train_triplets[0][0].shape)\n",
        "print(x_train_triplets[0][1].shape)\n",
        "print(x_train_triplets[0][2].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "sqxwJvnLOnwG"
      },
      "outputs": [],
      "source": [
        "def compute_gradients(W, x, reg, margin=1.0):\n",
        "    '''\n",
        "    Input:\n",
        "      W: Một mảng có kích thước (D, C) chứa các trọng số (weights).\n",
        "      X: Một mảng có kích thước (N, 3, D) chứa một lô nhỏ dữ liệu (mini-batch of data).\n",
        "      reg: (float) cường độ điều chuẩn (regularization strength).\n",
        "    Output:\n",
        "      Mất mát (loss) dưới dạng số thực (float).\n",
        "      Gradient đối với trọng số W; một mảng có kích thước giống như W.\n",
        "    '''\n",
        "\n",
        "    # print(x[:, 0, :].shape)\n",
        "    # print(x[:, 1, :].shape)\n",
        "    # print(x[:, 2, :].shape)\n",
        "    # print(W.shape)\n",
        "\n",
        "    loss = 0.0\n",
        "    dW = np.zeros_like(W)\n",
        "    N = x.shape[0]\n",
        "    anchor, positive, negative = x[:, 0, :], x[:, 1, :], x[:, 2, :]\n",
        "\n",
        "    scores_anchor = anchor.dot(W)\n",
        "    scores_positive = positive.dot(W)\n",
        "    scores_negative = negative.dot(W)\n",
        "\n",
        "    pos_dist = np.sum((scores_anchor - scores_positive) ** 2, axis=1)\n",
        "    neg_dist = np.sum((scores_anchor - scores_negative) ** 2, axis=1)\n",
        "\n",
        "    # Tính triplet_loss\n",
        "    loss = np.maximum(0, pos_dist - neg_dist + margin)\n",
        "    avg_loss = np.mean(loss)\n",
        "\n",
        "    # Tính gradient chỉ khi loss > 0\n",
        "    mask = (loss > 0).astype(float)\n",
        "\n",
        "    # Gradient của hàm mất mát theo điểm số\n",
        "    d_pos_dist = 2 * (scores_anchor - scores_positive)\n",
        "    d_neg_dist = 2 * (scores_anchor - scores_negative)\n",
        "\n",
        "    # Tính gradient đối với điểm số\n",
        "    dloss_danchor = (d_pos_dist - d_neg_dist) * mask[:, np.newaxis]\n",
        "    dloss_dpositive = -d_pos_dist * mask[:, np.newaxis]\n",
        "    dloss_dnegative = d_neg_dist * mask[:, np.newaxis]\n",
        "\n",
        "    # Tính gradient đối với trọng số W\n",
        "    dW = (anchor.T.dot(dloss_danchor) +\n",
        "          positive.T.dot(dloss_dpositive) +\n",
        "          negative.T.dot(dloss_dnegative)) / N\n",
        "\n",
        "    # Thêm cường độ điều chuẩn\n",
        "    dW += reg * W\n",
        "\n",
        "    # Tính toán mất mát với điều chuẩn\n",
        "    avg_loss += 0.5 * reg * np.sum(W * W)\n",
        "\n",
        "    return avg_loss, dW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Dmj3N73_uFMb"
      },
      "outputs": [],
      "source": [
        "W = np.random.randn(786, 300) * 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "XmooFKONLMCz"
      },
      "outputs": [],
      "source": [
        "avg_loss, W = compute_gradients(W,x_train_triplets[0:32], 0 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iiGIj7XuUXY",
        "outputId": "4641efcf-1448-447c-9722-eb3b6b15a692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5263285890127638\n"
          ]
        }
      ],
      "source": [
        "print(avg_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS9rYyzgVfkc",
        "outputId": "33487f19-593c-4b39-e5c9-9e920ad9f32c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Loss: 0.8827232869920849\n",
            "Epoch 2/20, Loss: 0.25975620806864125\n",
            "Epoch 3/20, Loss: 0.22281421976558916\n",
            "Epoch 4/20, Loss: 0.21112978721010517\n",
            "Epoch 5/20, Loss: 0.204939326127308\n",
            "Epoch 6/20, Loss: 0.20119423229397165\n",
            "Epoch 7/20, Loss: 0.19873228415418973\n",
            "Epoch 8/20, Loss: 0.19682254884223158\n",
            "Epoch 9/20, Loss: 0.19553122588464586\n",
            "Epoch 10/20, Loss: 0.1943048300496394\n",
            "Epoch 11/20, Loss: 0.19365675111653416\n",
            "Epoch 12/20, Loss: 0.19280051815695146\n",
            "Epoch 13/20, Loss: 0.19242539366955644\n",
            "Epoch 14/20, Loss: 0.19188356353846273\n",
            "Epoch 15/20, Loss: 0.19157996256568488\n",
            "Epoch 16/20, Loss: 0.19121840469059329\n",
            "Epoch 17/20, Loss: 0.1911777778702912\n",
            "Epoch 18/20, Loss: 0.1910326643027605\n",
            "Epoch 19/20, Loss: 0.19059971574002565\n",
            "Epoch 20/20, Loss: 0.19046726105621284\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "batch_size = 64\n",
        "learning_rate = 0.01\n",
        "reg = 0.01\n",
        "\n",
        "def update_weights(W, dW, learning_rate):\n",
        "    W -= learning_rate * dW\n",
        "    return W\n",
        "\n",
        "num_train = x_train_triplets.shape[0]\n",
        "num_batches = num_train // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # Chia dữ liệu thành các batch\n",
        "    for batch_idx in range(num_batches):\n",
        "        batch_start = batch_idx * batch_size\n",
        "        batch_end = (batch_idx + 1) * batch_size\n",
        "        x_batch = x_train_triplets[batch_start:batch_end]\n",
        "\n",
        "        # Tính toán loss và gradient\n",
        "        loss, dW = compute_gradients(W, x_batch, reg)\n",
        "        epoch_loss += loss\n",
        "\n",
        "        # Cập nhật trọng số\n",
        "        W = update_weights(W, dW, learning_rate)\n",
        "\n",
        "    # In ra mất mát trung bình của epoch\n",
        "    epoch_loss /= num_batches\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCJTW451wNDK"
      },
      "source": [
        "### Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "m6RIHl48wLvv"
      },
      "outputs": [],
      "source": [
        "def extract_features(W, X):\n",
        "    return X.dot(W)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "zAPiRBrZxD-9"
      },
      "outputs": [],
      "source": [
        "def euclidean_distance(x1, x2):\n",
        "    return np.sqrt(np.sum((x1 - x2)**2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "NmDFAvZzxE4W"
      },
      "outputs": [],
      "source": [
        "class KNN:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = [self._predict(x) for x in X]\n",
        "        return np.array(y_pred)\n",
        "\n",
        "    def _predict(self, x):\n",
        "        # Tính khoảng cách từ x tới tất cả các điểm trong X_train\n",
        "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
        "        # Lấy k láng giềng gần nhất\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
        "        # Lấy nhãn phổ biến nhất\n",
        "        most_common = np.bincount(k_nearest_labels).argmax()\n",
        "        return most_common"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0bnIpiurIof"
      },
      "outputs": [],
      "source": [
        "train_features = extract_features(W, x_train)\n",
        "test_features = extract_features(W, x_test)\n",
        "\n",
        "k = 3\n",
        "knn = KNN(k=k)\n",
        "knn.fit(train_features, y_train)\n",
        "# Dự đoán trên tập kiểm tra\n",
        "predictions = knn.predict(test_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYM7ZecZzacw"
      },
      "outputs": [],
      "source": [
        "# Tính độ chính xác\n",
        "accuracy = np.sum(predictions == y_test[0:1000]) / len(y_test[0:1000])\n",
        "print(f'Dộ chính xác của mô hình KNN là: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d64Hh_kBztkj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
